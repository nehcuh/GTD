#+TITLE: 模型评估与选择

* 经验误差与过拟合

- 错误率
- 精度
- 误差
- 训练误差 (training error) / 经验误差 (empirical error)
- 过拟合 (overfitting)
- 欠拟合 (underfitting)
- 模型选择 (model selection)

* 评估方法
** 留出法 (hold out)

#+BEGIN_QUOTE
留出法直接将数据集 $D$ 划分为两个互斥的集合，其中一个集合作为训练集 $S$, 另一个
作为测试集 $T$, 即 $D=S\cup T, S\cap T=\emptyset$, 在 $S$ 上训练出模型后，用 $T$
来评估其测试误差，作为对泛化能力的估计。
#+END_QUOTE

*单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，一般要采用若干次
随机划分，重复进行实验评估后取平均值作为留出法的评估结果*

** 交叉验证法 (cross validation)

#+BEGIN_QUOTE
交叉验证法先将数据集 $D$ 划分为 $k$ 个大小相似的互斥子集，即 $D=D_1\cup D_2\cup
\ldots \cup D_k, D_i \cap D_j = \emptyset (i\neq j)$, 每个子集 $D_i$ 都尽可能保
留数据分布的一致性，即从 $D$ 中通过分层采样得到，然后，每次用 $k-1$ 个子集并集作
为训练集，余下的那个子集作为测试集。通常把交叉验证法称为 "k 折交叉验证"。
#+END_QUOTE

*为了减小因样本划分不同而引入的差别， $k$ 折验交叉验证通常要进行多次。*

假定数据集 $D$ 中包含 $m$ 个样本，令 $k=m$, 得到了 $k$-折交叉法的特例，留一法，
虽然留一法不收随机样本划分方式的影响，但是增加了计算复杂度。

** 自助法 (bootstrapping)

留出法和交叉验证法由于保留了一部分样本作为测试，因此实际评估模型所用训练集比 $D$
小，必然会引入因样本规模不同导致的估计偏差。

#+BEGIN_QUOTE
自助法直接以自助采样法为基础，给定包含 $m$ 个样本的数据集 $D$, 对其进行采样产生
数据集 $D^{\prime}$: 每次从 $D$ 中挑选一个样本，将其拷贝放入 $D^{\prime}$, 然后
将样本放回样本数据集 $D$, 经过 $m$ 次样本，样本始终不被采集到的概率为
$(1-\frac{1}{m})^m$, 取极限有 $\lim\limits_{m\mapsto \infty} \mapsto \frac{1}{e}
\approx 0.368$. 于是，我们可以将 $D^{\prime}$ 作为训练集， $D\\D^{\prime}$ 作为
测试集，这样，实际评估的模型与期望评估的模型都使用 $m$ 个训练样本，我们仍有数据
总量的大约 $\frac{1}{3}$ 没在训练集中出现的样本用于测试，这样的测试结果，也成为
"包外估计" (out-of-bag estimate).
#+END_QUOTE

*自助法在数据集较小，难以有效划分训练集/测试集是很有用，此外，自助法能从初始数据
集中产生多个不同的训练集，对集成学习有很大帮助。*

自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。在初始数据量足够时，
一般采用留出法和交叉验证法。

** 调参与最终模型

给定包含 $m$ 个样本的数据集 $D$, 在模型评估与选择过程中，由于需要留出一部分数据
进行评估测试，事实上我们仅仅采用了一部分数据训练模型，因此，在模型选择完成后，学
习算法和参数配置已经选定，此时应该用数据集 $D$ 重新训练模型，这个模型在训练过程
中使用了所有 $m$ 个样本，这才是我们最终提交给用户的模型。

*我们通常将学得模型在实际使用中遇到的数据成为测试数据，为了加以区分，模型评估与
选择中用于评估测试的数据集通常称为验证集。*

* 性能度量

在预测任务中，给定样例集 $D=\left{ (\boldsymbol{x}_1, y_1),  (\boldsymbol{x}_2,
y_2), \ldots,  (\boldsymbol{x}_m, y_m)\right}$, 其中 $y_i$ 是示例
$\boldsymbol{x}_i$ 的真实标记，要评估学习器 $f$ 的性能，就需要把学习器预测结果
$f(\boldsymbol{x})$ 与真实标记 $y$ 进行比较。

回归任务最常用的性能度量是 “均方误差” (mean squared error)

\begin{equation}
    E(f; D) = \frac{1}{m}\sum\limits_{i=1}^m (f(\boldsymbol{x}_i_) - y_i)^2
\end{equation}

更一般地，对于数据分布 $\mathcal{D}$ 和概率密度函数 $p(\cdot)$, 均方误差可描述为

\begin{equation}
    E(f;D) = \int_{x\sim D}(f(\boldsymbol{x} - y)^2)p(\boldsymbol{x})d\boldsymbol{x}
\end{equation}

** 错误率与精度

- 对样例集 $D$, 分类错误率定义为

  \begin{equation}
    E(f;D) = \frac{1}{m}\sum\limits_{i=1}^m \mathbb{I}(f(\boldsymbol{x}_i)\neq y_i)
  \end{equation}

- 精度定义为：

 \begin{aligned}
    acc(f;D) &= \frac{1}{m}\sum\limits_{i=1}^m \mathbb{I}(f(\boldsymbol{x}_i)= y_i)\\
    &=1-E(f;D)
 \end{aligned}

- 更一般地，对于数据分布 $\mathcal{D}$ 和概率密度 $p(\cdot)$, 错误率与精度分别描
  述为

  \begin{equation}
    E(f;\mathcal{D}) = \int_{x\sim \mathcal{D}}\mathbb{I}(f(\symbolbold{x}\neq y))p(\symbolbold{x})d\symbolbold{x}
  \end{equation}


  \begin{aligned}
    acc(f;\mathcal{D}) &= \int_{x\sim \mathcal{D}}\mathbb{I}(f(\symbolbold{x}= y))p(\symbolbold{x})d\symbolbold{x}\\
    &= 1 - E(f;\mathcal{D})
  \end{aligned}

** 查准率、查全率与 F1

- 混淆矩阵

  | 真实情况 | 预测结果 |      |
  |----------+----------+------|
  |          | 正例     | 反例 |
  |----------+----------+------|
  | 正例     | TP       | FN   |
  | 反例     | FP       | TN   |

- 查准率 $P$ 和查全率 $R$ 定义为

  \begin{aligned}
    P &= \frac{TP}{TP+FP}\\
    R &= \frac{TP}{TP+FN}
  \end{aligned}

- P-R 曲线
- 平衡点 (Break-Even Point)
- F1 度量
\begin{equation}
    F1 = \frac{2\times P \times R}{P + R} = \frac{2\times TP}{样例总数 + TP - TN}
\end{equation}
- $F_\beta$ 定义

* 比较检验

* 偏差与方差
